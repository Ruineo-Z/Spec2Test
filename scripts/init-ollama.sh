#!/bin/bash
# Ollamaæ¨¡å‹åˆå§‹åŒ–è„šæœ¬
# ä¸‹è½½å’Œé…ç½®æœ¬åœ°LLMæ¨¡å‹

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# é»˜è®¤é…ç½®
OLLAMA_HOST="http://localhost:11434"
DEFAULT_MODEL="llama3.1:8b"
MODELS_TO_INSTALL=()

# æ‰“å°å¸¦é¢œè‰²çš„æ¶ˆæ¯
print_message() {
    local color=$1
    local message=$2
    echo -e "${color}${message}${NC}"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    cat << EOF
Ollamaæ¨¡å‹åˆå§‹åŒ–è„šæœ¬

ç”¨æ³•: $0 [é€‰é¡¹]

é€‰é¡¹:
    --host HOST             OllamaæœåŠ¡åœ°å€ [é»˜è®¤: http://localhost:11434]
    --model MODEL           è¦å®‰è£…çš„æ¨¡å‹ [é»˜è®¤: llama3.1:8b]
    --models MODEL1,MODEL2  è¦å®‰è£…çš„å¤šä¸ªæ¨¡å‹ï¼ˆé€—å·åˆ†éš”ï¼‰
    --list-available        åˆ—å‡ºå¯ç”¨æ¨¡å‹
    --list-installed        åˆ—å‡ºå·²å®‰è£…æ¨¡å‹
    --remove MODEL          åˆ é™¤æŒ‡å®šæ¨¡å‹
    -h, --help              æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

æ¨èæ¨¡å‹:
    llama3.1:8b            # 8Bå‚æ•°ï¼Œå¹³è¡¡æ€§èƒ½å’Œè´¨é‡
    llama3.1:70b           # 70Bå‚æ•°ï¼Œé«˜è´¨é‡ä½†éœ€è¦æ›´å¤šèµ„æº
    codellama:7b           # ä»£ç ç”Ÿæˆä¸“ç”¨æ¨¡å‹
    mistral:7b             # è½»é‡çº§é«˜æ€§èƒ½æ¨¡å‹
    qwen2:7b               # ä¸­æ–‡å‹å¥½æ¨¡å‹

ç¤ºä¾‹:
    $0                                          # å®‰è£…é»˜è®¤æ¨¡å‹
    $0 --model llama3.1:70b                     # å®‰è£…æŒ‡å®šæ¨¡å‹
    $0 --models llama3.1:8b,codellama:7b        # å®‰è£…å¤šä¸ªæ¨¡å‹
    $0 --list-available                         # åˆ—å‡ºå¯ç”¨æ¨¡å‹
    $0 --remove llama3.1:8b                     # åˆ é™¤æ¨¡å‹

EOF
}

# è§£æå‘½ä»¤è¡Œå‚æ•°
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --host)
                OLLAMA_HOST="$2"
                shift 2
                ;;
            --model)
                MODELS_TO_INSTALL=("$2")
                shift 2
                ;;
            --models)
                IFS=',' read -ra MODELS_TO_INSTALL <<< "$2"
                shift 2
                ;;
            --list-available)
                list_available_models
                exit 0
                ;;
            --list-installed)
                list_installed_models
                exit 0
                ;;
            --remove)
                remove_model "$2"
                exit 0
                ;;
            -h|--help)
                show_help
                exit 0
                ;;
            *)
                print_message $RED "æœªçŸ¥å‚æ•°: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
    if [[ ${#MODELS_TO_INSTALL[@]} -eq 0 ]]; then
        MODELS_TO_INSTALL=("$DEFAULT_MODEL")
    fi
}

# æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€
check_ollama_service() {
    print_message $YELLOW "ğŸ” æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€..."
    
    local max_retries=30
    local retry_count=0
    
    while [[ $retry_count -lt $max_retries ]]; do
        if curl -s "$OLLAMA_HOST/api/tags" > /dev/null 2>&1; then
            print_message $GREEN "âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸"
            return 0
        fi
        
        print_message $BLUE "â³ ç­‰å¾…OllamaæœåŠ¡å¯åŠ¨... ($((retry_count + 1))/$max_retries)"
        sleep 2
        retry_count=$((retry_count + 1))
    done
    
    print_message $RED "âŒ OllamaæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿æœåŠ¡å·²å¯åŠ¨"
    print_message $YELLOW "æç¤º: è¿è¡Œ 'docker-compose up ollama' å¯åŠ¨OllamaæœåŠ¡"
    exit 1
}

# åˆ—å‡ºå¯ç”¨æ¨¡å‹
list_available_models() {
    print_message $BLUE "ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:"
    print_message $GREEN "
ä»£ç ç”Ÿæˆæ¨¡å‹:
  â€¢ codellama:7b          - 7Bå‚æ•°ä»£ç ç”Ÿæˆæ¨¡å‹
  â€¢ codellama:13b         - 13Bå‚æ•°ä»£ç ç”Ÿæˆæ¨¡å‹
  â€¢ codellama:34b         - 34Bå‚æ•°ä»£ç ç”Ÿæˆæ¨¡å‹

é€šç”¨è¯­è¨€æ¨¡å‹:
  â€¢ llama3.1:8b           - 8Bå‚æ•°é€šç”¨æ¨¡å‹ï¼ˆæ¨èï¼‰
  â€¢ llama3.1:70b          - 70Bå‚æ•°é«˜è´¨é‡æ¨¡å‹
  â€¢ llama3.1:405b         - 405Bå‚æ•°é¡¶çº§æ¨¡å‹

è½»é‡çº§æ¨¡å‹:
  â€¢ mistral:7b            - 7Bå‚æ•°é«˜æ•ˆæ¨¡å‹
  â€¢ gemma:7b              - Google 7Bå‚æ•°æ¨¡å‹
  â€¢ qwen2:7b              - é˜¿é‡Œ7Bå‚æ•°ä¸­æ–‡å‹å¥½æ¨¡å‹

ä¸“ç”¨æ¨¡å‹:
  â€¢ llava:7b              - å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹
  â€¢ dolphin-mistral:7b    - å¯¹è¯ä¼˜åŒ–æ¨¡å‹
"
}

# åˆ—å‡ºå·²å®‰è£…æ¨¡å‹
list_installed_models() {
    print_message $YELLOW "ğŸ“‹ æ£€æŸ¥å·²å®‰è£…æ¨¡å‹..."
    
    if ! check_ollama_service_quiet; then
        print_message $RED "âŒ OllamaæœåŠ¡ä¸å¯ç”¨"
        exit 1
    fi
    
    local response=$(curl -s "$OLLAMA_HOST/api/tags")
    local models=$(echo "$response" | jq -r '.models[]?.name // empty' 2>/dev/null || echo "")
    
    if [[ -n "$models" ]]; then
        print_message $GREEN "âœ… å·²å®‰è£…çš„æ¨¡å‹:"
        echo "$models" | while read -r model; do
            if [[ -n "$model" ]]; then
                print_message $BLUE "  â€¢ $model"
            fi
        done
    else
        print_message $YELLOW "âš ï¸ æ²¡æœ‰å·²å®‰è£…çš„æ¨¡å‹"
    fi
}

# é™é»˜æ£€æŸ¥OllamaæœåŠ¡
check_ollama_service_quiet() {
    curl -s "$OLLAMA_HOST/api/tags" > /dev/null 2>&1
}

# å®‰è£…æ¨¡å‹
install_model() {
    local model=$1
    print_message $YELLOW "ğŸ“¥ å®‰è£…æ¨¡å‹: $model"
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å®‰è£…
    local installed_models=$(curl -s "$OLLAMA_HOST/api/tags" | jq -r '.models[]?.name // empty' 2>/dev/null || echo "")
    if echo "$installed_models" | grep -q "^$model$"; then
        print_message $GREEN "âœ… æ¨¡å‹ $model å·²å®‰è£…ï¼Œè·³è¿‡"
        return 0
    fi
    
    # å®‰è£…æ¨¡å‹
    print_message $BLUE "â¬‡ï¸ å¼€å§‹ä¸‹è½½æ¨¡å‹ $modelï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶ï¼‰..."
    
    if curl -X POST "$OLLAMA_HOST/api/pull" \
        -H "Content-Type: application/json" \
        -d "{\"name\":\"$model\"}" \
        --progress-bar \
        -o /dev/null; then
        print_message $GREEN "âœ… æ¨¡å‹ $model å®‰è£…æˆåŠŸ"
    else
        print_message $RED "âŒ æ¨¡å‹ $model å®‰è£…å¤±è´¥"
        return 1
    fi
}

# åˆ é™¤æ¨¡å‹
remove_model() {
    local model=$1
    print_message $YELLOW "ğŸ—‘ï¸ åˆ é™¤æ¨¡å‹: $model"
    
    if curl -X DELETE "$OLLAMA_HOST/api/delete" \
        -H "Content-Type: application/json" \
        -d "{\"name\":\"$model\"}"; then
        print_message $GREEN "âœ… æ¨¡å‹ $model åˆ é™¤æˆåŠŸ"
    else
        print_message $RED "âŒ æ¨¡å‹ $model åˆ é™¤å¤±è´¥"
        return 1
    fi
}

# æµ‹è¯•æ¨¡å‹
test_model() {
    local model=$1
    print_message $YELLOW "ğŸ§ª æµ‹è¯•æ¨¡å‹: $model"
    
    local test_prompt="Hello, please respond with 'Model is working correctly.'"
    local response=$(curl -s -X POST "$OLLAMA_HOST/api/generate" \
        -H "Content-Type: application/json" \
        -d "{\"model\":\"$model\",\"prompt\":\"$test_prompt\",\"stream\":false}")
    
    if echo "$response" | jq -e '.response' > /dev/null 2>&1; then
        local model_response=$(echo "$response" | jq -r '.response')
        print_message $GREEN "âœ… æ¨¡å‹ $model æµ‹è¯•æˆåŠŸ"
        print_message $BLUE "ğŸ“ æ¨¡å‹å“åº”: $model_response"
    else
        print_message $RED "âŒ æ¨¡å‹ $model æµ‹è¯•å¤±è´¥"
        return 1
    fi
}

# æ˜¾ç¤ºä½¿ç”¨å»ºè®®
show_usage_tips() {
    print_message $BLUE "ğŸ’¡ ä½¿ç”¨å»ºè®®:"
    print_message $GREEN "
1. æ¨¡å‹é€‰æ‹©å»ºè®®:
   â€¢ å¼€å‘æµ‹è¯•: llama3.1:8b (å¹³è¡¡æ€§èƒ½å’Œè´¨é‡)
   â€¢ ä»£ç ç”Ÿæˆ: codellama:7b (ä¸“é—¨ä¼˜åŒ–ä»£ç ä»»åŠ¡)
   â€¢ ç”Ÿäº§ç¯å¢ƒ: llama3.1:70b (é«˜è´¨é‡è¾“å‡º)

2. æ€§èƒ½ä¼˜åŒ–:
   â€¢ ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†…å­˜å’Œå­˜å‚¨ç©ºé—´
   â€¢ è€ƒè™‘ä½¿ç”¨GPUåŠ é€Ÿï¼ˆéœ€è¦NVIDIA GPUï¼‰
   â€¢ å®šæœŸæ¸…ç†ä¸ä½¿ç”¨çš„æ¨¡å‹

3. é…ç½®åº”ç”¨:
   â€¢ åœ¨.envæ–‡ä»¶ä¸­è®¾ç½® DEFAULT_LLM_PROVIDER=ollama
   â€¢ è®¾ç½® OLLAMA_BASE_URL=$OLLAMA_HOST
   â€¢ è®¾ç½® OLLAMA_MODEL=å·²å®‰è£…çš„æ¨¡å‹åç§°
"
}

# ä¸»å‡½æ•°
main() {
    print_message $BLUE "ğŸ¦™ Ollamaæ¨¡å‹åˆå§‹åŒ–è„šæœ¬"
    print_message $BLUE "=========================="
    
    parse_args "$@"
    
    print_message $BLUE "ğŸ”§ é…ç½®ä¿¡æ¯:"
    print_message $GREEN "  â€¢ Ollamaåœ°å€: $OLLAMA_HOST"
    print_message $GREEN "  â€¢ è¦å®‰è£…çš„æ¨¡å‹: ${MODELS_TO_INSTALL[*]}"
    
    check_ollama_service
    
    # å®‰è£…æ¨¡å‹
    local success_count=0
    local total_count=${#MODELS_TO_INSTALL[@]}
    
    for model in "${MODELS_TO_INSTALL[@]}"; do
        if install_model "$model"; then
            success_count=$((success_count + 1))
            test_model "$model"
        fi
    done
    
    print_message $BLUE "ğŸ“Š å®‰è£…ç»“æœ: $success_count/$total_count æˆåŠŸ"
    
    if [[ $success_count -eq $total_count ]]; then
        print_message $GREEN "ğŸ‰ æ‰€æœ‰æ¨¡å‹å®‰è£…å®Œæˆï¼"
        list_installed_models
        show_usage_tips
    else
        print_message $YELLOW "âš ï¸ éƒ¨åˆ†æ¨¡å‹å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
        exit 1
    fi
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    if ! command -v curl &> /dev/null; then
        print_message $RED "âŒ curlæœªå®‰è£…"
        exit 1
    fi
    
    if ! command -v jq &> /dev/null; then
        print_message $YELLOW "âš ï¸ jqæœªå®‰è£…ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨"
    fi
}

# æ£€æŸ¥ä¾èµ–å¹¶æ‰§è¡Œä¸»å‡½æ•°
check_dependencies
main "$@"
