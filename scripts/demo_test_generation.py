#!/usr/bin/env python3
"""
æµ‹è¯•ç”Ÿæˆå™¨æ¼”ç¤ºè„šæœ¬

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æµ‹è¯•ç”Ÿæˆå™¨æ ¹æ®APIæ–‡æ¡£åˆ†æç»“æœç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚
"""

import sys
import os
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.shared.utils.logger import get_logger
from app.core.document_analyzer import DocumentAnalyzer
from app.core.test_generator import TestCaseGenerator, GenerationConfig


def main():
    """ä¸»å‡½æ•°"""
    logger = get_logger(__name__)
    
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•ç”Ÿæˆå™¨æ¼”ç¤º...")
    
    try:
        # 1. åˆå§‹åŒ–æ–‡æ¡£åˆ†æå™¨
        logger.info("ğŸ“„ åˆå§‹åŒ–æ–‡æ¡£åˆ†æå™¨...")
        analyzer = DocumentAnalyzer()
        
        # 2. åˆ†æç¤ºä¾‹APIæ–‡æ¡£
        api_file = project_root / "examples" / "sample_api.json"
        if not api_file.exists():
            logger.error(f"ç¤ºä¾‹APIæ–‡ä»¶ä¸å­˜åœ¨: {api_file}")
            return
        
        logger.info(f"ğŸ“„ åˆ†ææ–‡æ¡£: {api_file}")
        analysis_result = analyzer.analyze_file(str(api_file))
        
        if not analysis_result.endpoints:
            logger.error("æ–‡æ¡£åˆ†æç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°APIç«¯ç‚¹")
            return
        
        logger.info(f"ğŸ“Š æ–‡æ¡£åˆ†æå®Œæˆ:")
        logger.info(f"   ğŸ“‹ æ–‡æ¡£æ ‡é¢˜: {analysis_result.title}")
        logger.info(f"   ğŸ”¢ APIç‰ˆæœ¬: {analysis_result.version}")
        logger.info(f"   ğŸŒ åŸºç¡€URL: {analysis_result.base_url}")
        logger.info(f"   ğŸ”— ç«¯ç‚¹æ•°é‡: {len(analysis_result.endpoints)}")
        
        # 3. åˆå§‹åŒ–æµ‹è¯•ç”Ÿæˆå™¨
        logger.info("ğŸ§ª åˆå§‹åŒ–æµ‹è¯•ç”Ÿæˆå™¨...")
        generator = TestCaseGenerator()
        
        # 4. é…ç½®ç”Ÿæˆå‚æ•°
        config = GenerationConfig(
            strategy="comprehensive",
            include_positive=True,
            include_negative=True,
            include_boundary=True,
            include_security=False,  # æš‚æ—¶å…³é—­å®‰å…¨æµ‹è¯•
            include_performance=False,  # æš‚æ—¶å…³é—­æ€§èƒ½æµ‹è¯•
            max_cases_per_endpoint=5,
            include_invalid_data=True,
            include_null_data=True,
            include_special_chars=True,
            llm_temperature=0.3,
            llm_max_tokens=4000
        )
        
        logger.info("âš™ï¸ ç”Ÿæˆé…ç½®:")
        logger.info(f"   ğŸ“‹ ç”Ÿæˆç­–ç•¥: {config.strategy}")
        logger.info(f"   âœ… æ­£å‘ç”¨ä¾‹: {config.include_positive}")
        logger.info(f"   âŒ è´Ÿå‘ç”¨ä¾‹: {config.include_negative}")
        logger.info(f"   ğŸ”„ è¾¹ç•Œç”¨ä¾‹: {config.include_boundary}")
        logger.info(f"   ğŸ”¢ æ¯ç«¯ç‚¹æœ€å¤§ç”¨ä¾‹æ•°: {config.max_cases_per_endpoint}")
        
        # 5. ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        logger.info("ğŸ¯ å¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
        generation_result = generator.generate_test_cases(analysis_result, config)
        
        # 6. æ˜¾ç¤ºç”Ÿæˆç»“æœ
        if generation_result.success:
            logger.info("âœ… æµ‹è¯•ç”¨ä¾‹ç”ŸæˆæˆåŠŸ!")
            
            test_suite = generation_result.test_suite
            logger.info(f"ğŸ“Š ç”Ÿæˆç»“æœç»Ÿè®¡:")
            logger.info(f"   ğŸ“¦ æµ‹è¯•å¥—ä»¶: {test_suite.name}")
            logger.info(f"   ğŸ”¢ ç”¨ä¾‹æ€»æ•°: {generation_result.total_cases_generated}")
            logger.info(f"   â±ï¸  ç”Ÿæˆè€—æ—¶: {generation_result.generation_duration:.2f}ç§’")
            logger.info(f"   ğŸ¤– LLMè°ƒç”¨æ¬¡æ•°: {generation_result.llm_calls_count}")
            
            # æŒ‰ç±»å‹ç»Ÿè®¡
            logger.info(f"   ğŸ“‹ æŒ‰ç±»å‹ç»Ÿè®¡:")
            for case_type, count in generation_result.cases_by_type.items():
                logger.info(f"      {case_type}: {count}ä¸ª")
            
            # æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
            logger.info(f"   ğŸ¯ æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡:")
            for priority, count in generation_result.cases_by_priority.items():
                logger.info(f"      {priority}: {count}ä¸ª")
            
            # æ˜¾ç¤ºéƒ¨åˆ†æµ‹è¯•ç”¨ä¾‹è¯¦æƒ…
            logger.info(f"\nğŸ” æµ‹è¯•ç”¨ä¾‹è¯¦æƒ…:")
            for i, test_case in enumerate(test_suite.test_cases[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                logger.info(f"   {i}. ğŸ“ {test_case.title}")
                logger.info(f"      ğŸ¯ ç±»å‹: {test_case.case_type.value}")
                logger.info(f"      â­ ä¼˜å…ˆçº§: {test_case.priority.value}")
                logger.info(f"      ğŸŒ ç«¯ç‚¹: {test_case.http_method.upper()} {test_case.endpoint_path}")
                logger.info(f"      ğŸ“Š çŠ¶æ€ç : {test_case.expected_status_code}")
                logger.info(f"      ğŸ” æ–­è¨€æ•°: {len(test_case.assertions)}")
                if test_case.tags:
                    logger.info(f"      ğŸ·ï¸  æ ‡ç­¾: {', '.join(test_case.tags)}")
                logger.info("")
            
            if len(test_suite.test_cases) > 3:
                logger.info(f"   ... è¿˜æœ‰ {len(test_suite.test_cases) - 3} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            
            # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
            if generation_result.has_warnings:
                logger.info(f"\nâš ï¸ è­¦å‘Šä¿¡æ¯:")
                for warning in generation_result.warnings:
                    logger.info(f"   - {warning}")
            
            # 7. å¯¼å‡ºæµ‹è¯•ç”¨ä¾‹
            logger.info("\nğŸ“„ å¯¼å‡ºæµ‹è¯•ç”¨ä¾‹...")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = project_root / "examples" / "test_generation_results"
            output_dir.mkdir(exist_ok=True)
            
            # å¯¼å‡ºJSONæ ¼å¼
            json_file = output_dir / "generated_test_cases.json"
            test_suite_dict = test_suite.model_dump()
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(test_suite_dict, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"   âœ… JSONæ–‡ä»¶: {json_file}")
            
            # å¯¼å‡ºç”Ÿæˆç»“æœ
            result_file = output_dir / "generation_result.json"
            result_dict = generation_result.model_dump()
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(result_dict, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"   âœ… ç»“æœæ–‡ä»¶: {result_file}")
            
            # å¯¼å‡ºMarkdownæ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹
            md_file = output_dir / "test_cases.md"
            _export_markdown_test_cases(test_suite, md_file)
            logger.info(f"   âœ… Markdownæ–‡ä»¶: {md_file}")
            
        else:
            logger.error("âŒ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥!")
            logger.error(f"   é”™è¯¯ä¿¡æ¯:")
            for error in generation_result.errors:
                logger.error(f"   - {error}")
        
        logger.info("\nğŸ‰ æµ‹è¯•ç”Ÿæˆå™¨æ¼”ç¤ºå®Œæˆ!")
        if 'output_dir' in locals():
            logger.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")
        else:
            logger.info("ğŸ“ ç”±äºç”Ÿæˆå¤±è´¥ï¼Œæœªåˆ›å»ºè¾“å‡ºæ–‡ä»¶")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ æµ‹è¯•ç”Ÿæˆå™¨æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


def _export_markdown_test_cases(test_suite, output_file):
    """å¯¼å‡ºMarkdownæ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹"""
    
    content = []
    content.append(f"# {test_suite.name}")
    content.append("")
    content.append(f"**æè¿°**: {test_suite.description}")
    content.append(f"**åŸºç¡€URL**: {test_suite.base_url or 'N/A'}")
    content.append(f"**ç”¨ä¾‹æ€»æ•°**: {test_suite.total_cases}")
    content.append(f"**åˆ›å»ºæ—¶é—´**: {test_suite.created_at}")
    content.append("")
    
    # æŒ‰ç«¯ç‚¹åˆ†ç»„
    endpoints = {}
    for case in test_suite.test_cases:
        endpoint_key = f"{case.http_method.upper()} {case.endpoint_path}"
        if endpoint_key not in endpoints:
            endpoints[endpoint_key] = []
        endpoints[endpoint_key].append(case)
    
    for endpoint, cases in endpoints.items():
        content.append(f"## {endpoint}")
        content.append("")
        
        for i, case in enumerate(cases, 1):
            content.append(f"### {i}. {case.title}")
            content.append("")
            content.append(f"**æè¿°**: {case.description}")
            content.append(f"**ç±»å‹**: {case.case_type.value}")
            content.append(f"**ä¼˜å…ˆçº§**: {case.priority.value}")
            content.append(f"**é¢„æœŸçŠ¶æ€ç **: {case.expected_status_code}")
            
            if case.tags:
                content.append(f"**æ ‡ç­¾**: {', '.join(case.tags)}")
            
            # è¯·æ±‚ä¿¡æ¯
            if case.request_headers:
                content.append("")
                content.append("**è¯·æ±‚å¤´**:")
                content.append("```json")
                content.append(json.dumps(case.request_headers, indent=2, ensure_ascii=False))
                content.append("```")
            
            if case.request_params:
                content.append("")
                content.append("**è¯·æ±‚å‚æ•°**:")
                content.append("```json")
                content.append(json.dumps(case.request_params, indent=2, ensure_ascii=False))
                content.append("```")
            
            if case.request_body:
                content.append("")
                content.append("**è¯·æ±‚ä½“**:")
                content.append("```json")
                content.append(json.dumps(case.request_body, indent=2, ensure_ascii=False))
                content.append("```")
            
            # æ–­è¨€ä¿¡æ¯
            if case.assertions:
                content.append("")
                content.append("**æ–­è¨€éªŒè¯**:")
                for assertion in case.assertions:
                    content.append(f"- {assertion.description}")
            
            content.append("")
            content.append("---")
            content.append("")
    
    # å†™å…¥æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(content))


if __name__ == "__main__":
    main()
