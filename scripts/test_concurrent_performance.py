#!/usr/bin/env python3
"""
å¹¶å‘æ€§èƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•ä¸²è¡Œvså¹¶å‘ç”Ÿæˆçš„æ€§èƒ½å·®å¼‚ã€‚
"""

import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.shared.utils.logger import get_logger
from app.core.document_analyzer import DocumentAnalyzer
from app.core.test_generator import TestCaseGenerator, GenerationConfig
from app.core.test_generator.concurrent_generator import (
    ConcurrentTestCaseGenerator, 
    AdaptiveTestCaseGenerator,
    PerformanceComparator
)


def test_concurrent_performance():
    """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
    logger = get_logger(__name__)
    
    logger.info("ğŸš€ å¼€å§‹å¹¶å‘æ€§èƒ½æµ‹è¯•...")
    
    try:
        # 1. åˆ†æç¤ºä¾‹APIæ–‡æ¡£
        analyzer = DocumentAnalyzer()
        api_file = project_root / "examples" / "sample_api.json"
        
        logger.info(f"ğŸ“„ åˆ†ææ–‡æ¡£: {api_file}")
        analysis_result = analyzer.analyze_file(str(api_file))
        
        logger.info(f"ğŸ“Š åˆ†æç»“æœ: {len(analysis_result.endpoints)}ä¸ªç«¯ç‚¹")
        for i, endpoint in enumerate(analysis_result.endpoints, 1):
            logger.info(f"   {i}. {endpoint.method.upper()} {endpoint.path}")
        
        # 2. é…ç½®ç”Ÿæˆå‚æ•°
        config = GenerationConfig(
            include_positive=True,
            include_negative=True,
            include_boundary=False,
            max_cases_per_endpoint=3,
            enable_concurrent=True,
            max_concurrent_workers=3
        )
        
        # 3. ä¸²è¡Œç”Ÿæˆæµ‹è¯•
        logger.info("\nğŸ”„ æµ‹è¯•ä¸²è¡Œç”Ÿæˆ...")
        serial_generator = TestCaseGenerator()
        
        serial_start = time.time()
        serial_result = serial_generator.generate_test_cases(analysis_result, config)
        serial_duration = time.time() - serial_start
        
        logger.info(f"ä¸²è¡Œç”Ÿæˆç»“æœ:")
        logger.info(f"   â±ï¸  è€—æ—¶: {serial_duration:.2f}ç§’")
        logger.info(f"   ğŸ“Š ç”¨ä¾‹æ•°: {serial_result.total_cases_generated}")
        logger.info(f"   ğŸ¤– LLMè°ƒç”¨: {serial_result.llm_calls_count}æ¬¡")
        logger.info(f"   âœ… æˆåŠŸ: {serial_result.success}")
        
        # 4. å¹¶å‘ç”Ÿæˆæµ‹è¯•
        logger.info("\nâš¡ æµ‹è¯•å¹¶å‘ç”Ÿæˆ...")
        concurrent_generator = ConcurrentTestCaseGenerator(max_workers=3)
        
        concurrent_start = time.time()
        concurrent_result = concurrent_generator.generate_test_cases_concurrent(analysis_result, config)
        concurrent_duration = time.time() - concurrent_start
        
        logger.info(f"å¹¶å‘ç”Ÿæˆç»“æœ:")
        logger.info(f"   â±ï¸  è€—æ—¶: {concurrent_duration:.2f}ç§’")
        logger.info(f"   ğŸ“Š ç”¨ä¾‹æ•°: {concurrent_result.total_cases_generated}")
        logger.info(f"   ğŸ¤– LLMè°ƒç”¨: {concurrent_result.llm_calls_count}æ¬¡")
        logger.info(f"   âœ… æˆåŠŸ: {concurrent_result.success}")
        
        # 5. æ€§èƒ½å¯¹æ¯”
        if serial_duration > 0:
            improvement = (serial_duration - concurrent_duration) / serial_duration * 100
            speedup = serial_duration / concurrent_duration if concurrent_duration > 0 else float('inf')
            
            logger.info(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
            logger.info(f"   âš¡ æ€§èƒ½æå‡: {improvement:.1f}%")
            logger.info(f"   ğŸš€ åŠ é€Ÿæ¯”: {speedup:.2f}x")
            logger.info(f"   â° æ—¶é—´èŠ‚çœ: {serial_duration - concurrent_duration:.2f}ç§’")
            
            # åˆ¤æ–­å¹¶å‘æ•ˆæœ
            if improvement > 30:
                logger.info("   ğŸ‰ å¹¶å‘æ•ˆæœæ˜¾è‘—ï¼")
            elif improvement > 10:
                logger.info("   ğŸ‘ å¹¶å‘æ•ˆæœè‰¯å¥½")
            elif improvement > 0:
                logger.info("   ğŸ“Š å¹¶å‘æœ‰è½»å¾®æå‡")
            else:
                logger.info("   âš ï¸  å¹¶å‘æœªå¸¦æ¥æ€§èƒ½æå‡")
        
        # 6. æµ‹è¯•è‡ªé€‚åº”ç”Ÿæˆå™¨
        logger.info("\nğŸ§  æµ‹è¯•è‡ªé€‚åº”ç”Ÿæˆå™¨...")
        adaptive_generator = AdaptiveTestCaseGenerator()
        
        adaptive_start = time.time()
        adaptive_result = adaptive_generator.generate_test_cases_adaptive(analysis_result, config)
        adaptive_duration = time.time() - adaptive_start
        
        logger.info(f"è‡ªé€‚åº”ç”Ÿæˆç»“æœ:")
        logger.info(f"   â±ï¸  è€—æ—¶: {adaptive_duration:.2f}ç§’")
        logger.info(f"   ğŸ“Š ç”¨ä¾‹æ•°: {adaptive_result.total_cases_generated}")
        logger.info(f"   âœ… æˆåŠŸ: {adaptive_result.success}")
        
        # 7. è´¨é‡éªŒè¯
        logger.info(f"\nğŸ” è´¨é‡éªŒè¯:")
        
        # æ£€æŸ¥ç”¨ä¾‹æ•°é‡ä¸€è‡´æ€§
        if (serial_result.total_cases_generated == concurrent_result.total_cases_generated == 
            adaptive_result.total_cases_generated):
            logger.info("   âœ… ç”¨ä¾‹æ•°é‡ä¸€è‡´")
        else:
            logger.info("   âš ï¸  ç”¨ä¾‹æ•°é‡ä¸ä¸€è‡´")
            logger.info(f"      ä¸²è¡Œ: {serial_result.total_cases_generated}")
            logger.info(f"      å¹¶å‘: {concurrent_result.total_cases_generated}")
            logger.info(f"      è‡ªé€‚åº”: {adaptive_result.total_cases_generated}")
        
        # æ£€æŸ¥æˆåŠŸç‡
        success_count = sum([serial_result.success, concurrent_result.success, adaptive_result.success])
        logger.info(f"   ğŸ“Š æˆåŠŸç‡: {success_count}/3 ({success_count/3*100:.1f}%)")
        
        return True
        
    except Exception as e:
        logger.error(f"ğŸ’¥ å¹¶å‘æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def test_scalability():
    """æµ‹è¯•å¯æ‰©å±•æ€§ï¼ˆæ¨¡æ‹Ÿæ›´å¤šç«¯ç‚¹ï¼‰"""
    logger = get_logger("test_scalability")
    
    logger.info("ğŸ“ˆ å¼€å§‹å¯æ‰©å±•æ€§æµ‹è¯•...")
    
    try:
        # åˆ†ææ–‡æ¡£
        analyzer = DocumentAnalyzer()
        api_file = project_root / "examples" / "sample_api.json"
        analysis_result = analyzer.analyze_file(str(api_file))
        
        # æ¨¡æ‹Ÿæ›´å¤šç«¯ç‚¹ï¼ˆå¤åˆ¶ç°æœ‰ç«¯ç‚¹ï¼‰
        original_endpoints = analysis_result.endpoints.copy()
        
        # æµ‹è¯•ä¸åŒç«¯ç‚¹æ•°é‡çš„æ€§èƒ½
        endpoint_counts = [3, 6, 9]  # 3, 6, 9ä¸ªç«¯ç‚¹
        
        for count in endpoint_counts:
            logger.info(f"\nğŸ”¢ æµ‹è¯• {count} ä¸ªç«¯ç‚¹...")
            
            # å¤åˆ¶ç«¯ç‚¹åˆ°æŒ‡å®šæ•°é‡
            analysis_result.endpoints = original_endpoints * (count // len(original_endpoints))
            analysis_result.endpoints = analysis_result.endpoints[:count]
            
            config = GenerationConfig(
                include_positive=True,
                include_negative=False,  # ç®€åŒ–æµ‹è¯•
                max_cases_per_endpoint=2,  # å‡å°‘æ¯ä¸ªç«¯ç‚¹çš„ç”¨ä¾‹æ•°
                max_concurrent_workers=3
            )
            
            # ä¸²è¡Œæµ‹è¯•
            serial_generator = TestCaseGenerator()
            serial_start = time.time()
            serial_result = serial_generator.generate_test_cases(analysis_result, config)
            serial_duration = time.time() - serial_start
            
            # å¹¶å‘æµ‹è¯•
            concurrent_generator = ConcurrentTestCaseGenerator(max_workers=3)
            concurrent_start = time.time()
            concurrent_result = concurrent_generator.generate_test_cases_concurrent(analysis_result, config)
            concurrent_duration = time.time() - concurrent_start
            
            # è®¡ç®—æ€§èƒ½æå‡
            improvement = (serial_duration - concurrent_duration) / serial_duration * 100 if serial_duration > 0 else 0
            
            logger.info(f"   ç«¯ç‚¹æ•°: {count}")
            logger.info(f"   ä¸²è¡Œ: {serial_duration:.2f}ç§’")
            logger.info(f"   å¹¶å‘: {concurrent_duration:.2f}ç§’")
            logger.info(f"   æå‡: {improvement:.1f}%")
        
        return True
        
    except Exception as e:
        logger.error(f"ğŸ’¥ å¯æ‰©å±•æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger = get_logger(__name__)
    
    logger.info("ğŸš€ å¼€å§‹å¹¶å‘æ€§èƒ½æµ‹è¯•å¥—ä»¶...")
    
    tests = [
        ("å¹¶å‘æ€§èƒ½æµ‹è¯•", test_concurrent_performance),
        ("å¯æ‰©å±•æ€§æµ‹è¯•", test_scalability),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ æ‰§è¡Œ: {test_name}")
        try:
            if test_func():
                passed += 1
                logger.info(f"âœ… {test_name} é€šè¿‡")
            else:
                logger.error(f"âŒ {test_name} å¤±è´¥")
        except Exception as e:
            logger.error(f"ğŸ’¥ {test_name} å¼‚å¸¸: {e}")
    
    logger.info(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    logger.info(f"   æ€»æµ‹è¯•æ•°: {total}")
    logger.info(f"   é€šè¿‡æ•°: {passed}")
    logger.info(f"   å¤±è´¥æ•°: {total - passed}")
    logger.info(f"   é€šè¿‡ç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
    else:
        logger.error("ğŸ’¥ éƒ¨åˆ†æµ‹è¯•å¤±è´¥!")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
