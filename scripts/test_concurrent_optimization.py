#!/usr/bin/env python3
"""
å¹¶å‘ä¼˜åŒ–æµ‹è¯•è„šæœ¬

æµ‹è¯•ä¸åŒLLMæä¾›å•†å’Œå¹¶å‘æ•°é…ç½®çš„æ€§èƒ½è¡¨ç°ã€‚
"""

import sys
import time
import os
from pathlib import Path
from typing import Dict, List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.shared.utils.logger import get_logger
from app.core.document_analyzer import DocumentAnalyzer
from app.core.test_generator import TestCaseGenerator, GenerationConfig
from app.core.test_generator.concurrent_generator import ConcurrentTestCaseGenerator


def test_ollama_concurrent_scaling():
    """æµ‹è¯•Ollamaçš„å¹¶å‘æ‰©å±•æ€§"""
    logger = get_logger("test_ollama_scaling")
    
    logger.info("ğŸ”„ æµ‹è¯•Ollamaå¹¶å‘æ‰©å±•æ€§...")
    
    # åˆ†ææ–‡æ¡£
    analyzer = DocumentAnalyzer()
    api_file = project_root / "examples" / "sample_api.json"
    analysis_result = analyzer.analyze_file(str(api_file))
    
    # æµ‹è¯•ä¸åŒå¹¶å‘æ•°
    concurrent_workers = [1, 2, 3, 4, 5]
    results = []
    
    for workers in concurrent_workers:
        logger.info(f"\nğŸ“Š æµ‹è¯• {workers} ä¸ªå¹¶å‘çº¿ç¨‹...")
        
        try:
            # é…ç½®
            config = GenerationConfig(
                include_positive=True,
                include_negative=False,
                max_cases_per_endpoint=2,
                max_concurrent_workers=workers
            )
            
            # å¹¶å‘ç”Ÿæˆ
            generator = ConcurrentTestCaseGenerator(max_workers=workers)
            start_time = time.time()
            result = generator.generate_test_cases_concurrent(analysis_result, config)
            duration = time.time() - start_time
            
            results.append({
                "workers": workers,
                "duration": duration,
                "cases": result.total_cases_generated,
                "success": result.success
            })
            
            logger.info(f"   â±ï¸  è€—æ—¶: {duration:.2f}ç§’")
            logger.info(f"   ğŸ“Š ç”¨ä¾‹æ•°: {result.total_cases_generated}")
            logger.info(f"   âœ… æˆåŠŸ: {result.success}")
            
        except Exception as e:
            logger.error(f"   âŒ å¤±è´¥: {e}")
            results.append({
                "workers": workers,
                "duration": float('inf'),
                "cases": 0,
                "success": False
            })
    
    # åˆ†æç»“æœ
    logger.info(f"\nğŸ“ˆ Ollamaå¹¶å‘æ‰©å±•æ€§åˆ†æ:")
    logger.info(f"{'å¹¶å‘æ•°':<8} {'è€—æ—¶(ç§’)':<10} {'ç”¨ä¾‹æ•°':<8} {'æ•ˆç‡':<10}")
    logger.info("-" * 40)
    
    baseline_duration = None
    for result in results:
        if result["success"]:
            if baseline_duration is None:
                baseline_duration = result["duration"]
                efficiency = "åŸºå‡†"
            else:
                speedup = baseline_duration / result["duration"]
                efficiency = f"{speedup:.2f}x"
            
            logger.info(f"{result['workers']:<8} {result['duration']:<10.2f} {result['cases']:<8} {efficiency:<10}")
        else:
            logger.info(f"{result['workers']:<8} {'å¤±è´¥':<10} {result['cases']:<8} {'N/A':<10}")
    
    return results


def test_gemini_concurrent_performance():
    """æµ‹è¯•Geminiçš„å¹¶å‘æ€§èƒ½ï¼ˆå¦‚æœé…ç½®äº†APIå¯†é’¥ï¼‰"""
    logger = get_logger("test_gemini_performance")
    
    # æ£€æŸ¥æ˜¯å¦é…ç½®äº†Gemini APIå¯†é’¥
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if not gemini_api_key:
        logger.info("âš ï¸  æœªé…ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡ï¼Œè·³è¿‡Geminiæµ‹è¯•")
        return None
    
    logger.info("â˜ï¸  æµ‹è¯•Geminiå¹¶å‘æ€§èƒ½...")
    
    try:
        # åˆ†ææ–‡æ¡£
        analyzer = DocumentAnalyzer()
        api_file = project_root / "examples" / "sample_api.json"
        analysis_result = analyzer.analyze_file(str(api_file))
        
        # Geminié…ç½®
        gemini_config = {
            "provider": "gemini",
            "api_key": gemini_api_key,
            "model": "gemini-pro",
            "temperature": 0.3,
            "max_tokens": 4000
        }
        
        # æµ‹è¯•ä¸åŒå¹¶å‘æ•°
        concurrent_workers = [1, 3, 5, 8, 10]
        results = []
        
        for workers in concurrent_workers:
            logger.info(f"\nğŸ“Š æµ‹è¯•Gemini {workers}ä¸ªå¹¶å‘çº¿ç¨‹...")
            
            try:
                config = GenerationConfig(
                    include_positive=True,
                    include_negative=False,
                    max_cases_per_endpoint=2,
                    max_concurrent_workers=workers
                )
                
                generator = ConcurrentTestCaseGenerator(gemini_config, max_workers=workers)
                start_time = time.time()
                result = generator.generate_test_cases_concurrent(analysis_result, config)
                duration = time.time() - start_time
                
                results.append({
                    "workers": workers,
                    "duration": duration,
                    "cases": result.total_cases_generated,
                    "success": result.success
                })
                
                logger.info(f"   â±ï¸  è€—æ—¶: {duration:.2f}ç§’")
                logger.info(f"   ğŸ“Š ç”¨ä¾‹æ•°: {result.total_cases_generated}")
                logger.info(f"   âœ… æˆåŠŸ: {result.success}")
                
            except Exception as e:
                logger.error(f"   âŒ å¤±è´¥: {e}")
                results.append({
                    "workers": workers,
                    "duration": float('inf'),
                    "cases": 0,
                    "success": False
                })
        
        # åˆ†æç»“æœ
        logger.info(f"\nğŸ“ˆ Geminiå¹¶å‘æ‰©å±•æ€§åˆ†æ:")
        logger.info(f"{'å¹¶å‘æ•°':<8} {'è€—æ—¶(ç§’)':<10} {'ç”¨ä¾‹æ•°':<8} {'æ•ˆç‡':<10}")
        logger.info("-" * 40)
        
        baseline_duration = None
        for result in results:
            if result["success"]:
                if baseline_duration is None:
                    baseline_duration = result["duration"]
                    efficiency = "åŸºå‡†"
                else:
                    speedup = baseline_duration / result["duration"]
                    efficiency = f"{speedup:.2f}x"
                
                logger.info(f"{result['workers']:<8} {result['duration']:<10.2f} {result['cases']:<8} {efficiency:<10}")
            else:
                logger.info(f"{result['workers']:<8} {'å¤±è´¥':<10} {result['cases']:<8} {'N/A':<10}")
        
        return results
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Geminiæµ‹è¯•å¤±è´¥: {e}")
        return None


def compare_providers_performance():
    """å¯¹æ¯”ä¸åŒæä¾›å•†çš„æ€§èƒ½"""
    logger = get_logger("compare_providers")
    
    logger.info("ğŸ†š å¯¹æ¯”ä¸åŒLLMæä¾›å•†æ€§èƒ½...")
    
    # åˆ†ææ–‡æ¡£
    analyzer = DocumentAnalyzer()
    api_file = project_root / "examples" / "sample_api.json"
    analysis_result = analyzer.analyze_file(str(api_file))
    
    providers_config = [
        {
            "name": "Ollama",
            "config": {
                "provider": "ollama",
                "base_url": "http://localhost:11434",
                "model": "qwen2.5:3b",
                "temperature": 0.3
            },
            "optimal_workers": 2
        }
    ]
    
    # å¦‚æœæœ‰Gemini APIå¯†é’¥ï¼Œæ·»åŠ Geminiæµ‹è¯•
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if gemini_api_key:
        providers_config.append({
            "name": "Gemini",
            "config": {
                "provider": "gemini",
                "api_key": gemini_api_key,
                "model": "gemini-pro",
                "temperature": 0.3
            },
            "optimal_workers": 5
        })
    
    results = []
    
    for provider_info in providers_config:
        name = provider_info["name"]
        config = provider_info["config"]
        workers = provider_info["optimal_workers"]
        
        logger.info(f"\nğŸ§ª æµ‹è¯• {name} (å¹¶å‘æ•°: {workers})...")
        
        try:
            gen_config = GenerationConfig(
                include_positive=True,
                include_negative=False,
                max_cases_per_endpoint=2,
                max_concurrent_workers=workers
            )
            
            # ä¸²è¡Œæµ‹è¯•
            serial_generator = TestCaseGenerator(config)
            start_time = time.time()
            serial_result = serial_generator.generate_test_cases(analysis_result, gen_config)
            serial_duration = time.time() - start_time
            
            # å¹¶å‘æµ‹è¯•
            concurrent_generator = ConcurrentTestCaseGenerator(config, max_workers=workers)
            start_time = time.time()
            concurrent_result = concurrent_generator.generate_test_cases_concurrent(analysis_result, gen_config)
            concurrent_duration = time.time() - start_time
            
            # è®¡ç®—æå‡
            improvement = (serial_duration - concurrent_duration) / serial_duration * 100 if serial_duration > 0 else 0
            
            result = {
                "provider": name,
                "workers": workers,
                "serial_duration": serial_duration,
                "concurrent_duration": concurrent_duration,
                "improvement": improvement,
                "serial_cases": serial_result.total_cases_generated,
                "concurrent_cases": concurrent_result.total_cases_generated,
                "success": serial_result.success and concurrent_result.success
            }
            
            results.append(result)
            
            logger.info(f"   ä¸²è¡Œ: {serial_duration:.2f}ç§’, {serial_result.total_cases_generated}ç”¨ä¾‹")
            logger.info(f"   å¹¶å‘: {concurrent_duration:.2f}ç§’, {concurrent_result.total_cases_generated}ç”¨ä¾‹")
            logger.info(f"   æå‡: {improvement:.1f}%")
            
        except Exception as e:
            logger.error(f"   âŒ {name} æµ‹è¯•å¤±è´¥: {e}")
            results.append({
                "provider": name,
                "workers": workers,
                "serial_duration": float('inf'),
                "concurrent_duration": float('inf'),
                "improvement": 0,
                "success": False
            })
    
    # æ€»ç»“å¯¹æ¯”
    logger.info(f"\nğŸ“Š æä¾›å•†æ€§èƒ½å¯¹æ¯”æ€»ç»“:")
    logger.info(f"{'æä¾›å•†':<10} {'å¹¶å‘æ•°':<8} {'ä¸²è¡Œ(ç§’)':<10} {'å¹¶å‘(ç§’)':<10} {'æå‡':<10}")
    logger.info("-" * 55)
    
    for result in results:
        if result["success"]:
            logger.info(f"{result['provider']:<10} {result['workers']:<8} {result['serial_duration']:<10.2f} {result['concurrent_duration']:<10.2f} {result['improvement']:<10.1f}%")
        else:
            logger.info(f"{result['provider']:<10} {result['workers']:<8} {'å¤±è´¥':<10} {'å¤±è´¥':<10} {'N/A':<10}")
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    logger = get_logger(__name__)
    
    logger.info("ğŸš€ å¼€å§‹å¹¶å‘ä¼˜åŒ–æµ‹è¯•...")
    
    tests = [
        ("Ollamaå¹¶å‘æ‰©å±•æ€§", test_ollama_concurrent_scaling),
        ("Geminiå¹¶å‘æ€§èƒ½", test_gemini_concurrent_performance),
        ("æä¾›å•†æ€§èƒ½å¯¹æ¯”", compare_providers_performance),
    ]
    
    all_results = {}
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ æ‰§è¡Œ: {test_name}")
        try:
            result = test_func()
            all_results[test_name] = result
            if result is not None:
                logger.info(f"âœ… {test_name} å®Œæˆ")
            else:
                logger.info(f"âš ï¸  {test_name} è·³è¿‡")
        except Exception as e:
            logger.error(f"ğŸ’¥ {test_name} å¼‚å¸¸: {e}")
            all_results[test_name] = None
    
    # æœ€ç»ˆå»ºè®®
    logger.info(f"\nğŸ¯ å¹¶å‘ä¼˜åŒ–å»ºè®®:")
    
    if all_results.get("Ollamaå¹¶å‘æ‰©å±•æ€§"):
        ollama_results = all_results["Ollamaå¹¶å‘æ‰©å±•æ€§"]
        best_ollama = min([r for r in ollama_results if r["success"]], key=lambda x: x["duration"], default=None)
        if best_ollama:
            logger.info(f"   ğŸ–¥ï¸  Ollamaæœ€ä¼˜å¹¶å‘æ•°: {best_ollama['workers']} (è€—æ—¶: {best_ollama['duration']:.2f}ç§’)")
    
    if all_results.get("Geminiå¹¶å‘æ€§èƒ½"):
        gemini_results = all_results["Geminiå¹¶å‘æ€§èƒ½"]
        if gemini_results:
            best_gemini = min([r for r in gemini_results if r["success"]], key=lambda x: x["duration"], default=None)
            if best_gemini:
                logger.info(f"   â˜ï¸  Geminiæœ€ä¼˜å¹¶å‘æ•°: {best_gemini['workers']} (è€—æ—¶: {best_gemini['duration']:.2f}ç§’)")
    
    if all_results.get("æä¾›å•†æ€§èƒ½å¯¹æ¯”"):
        comparison = all_results["æä¾›å•†æ€§èƒ½å¯¹æ¯”"]
        if comparison:
            best_provider = max([r for r in comparison if r["success"]], key=lambda x: x["improvement"], default=None)
            if best_provider:
                logger.info(f"   ğŸ† æœ€ä½³æä¾›å•†: {best_provider['provider']} (æå‡: {best_provider['improvement']:.1f}%)")
    
    logger.info(f"\nğŸ‰ å¹¶å‘ä¼˜åŒ–æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()
