"""
ä»»åŠ¡ç›‘æ§å’Œç»Ÿè®¡

æä¾›ä»»åŠ¡æ‰§è¡Œçš„ç›‘æ§ã€æŒ‡æ ‡æ”¶é›†å’Œç»Ÿè®¡åˆ†æåŠŸèƒ½ã€‚
"""

import asyncio
import time
from typing import Dict, Any, List, Optional, Callable
from datetime import datetime, timedelta
from collections import defaultdict, deque
from dataclasses import dataclass, field

from .models import TaskStatus, TaskType, TaskModel
from app.core.shared.utils.logger import get_logger

logger = get_logger(__name__)


@dataclass
class TaskMetrics:
    """ä»»åŠ¡æŒ‡æ ‡"""
    task_id: str
    task_type: TaskType
    status: TaskStatus
    
    # æ—¶é—´æŒ‡æ ‡
    created_at: datetime
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    
    # æ€§èƒ½æŒ‡æ ‡
    execution_time: Optional[float] = None
    queue_time: Optional[float] = None
    retry_count: int = 0
    
    # èµ„æºæŒ‡æ ‡
    memory_usage_mb: Optional[float] = None
    cpu_usage_percent: Optional[float] = None
    
    def calculate_times(self):
        """è®¡ç®—æ—¶é—´æŒ‡æ ‡"""
        if self.started_at:
            self.queue_time = (self.started_at - self.created_at).total_seconds()
        
        if self.started_at and self.completed_at:
            self.execution_time = (self.completed_at - self.started_at).total_seconds()


@dataclass
class SystemMetrics:
    """ç³»ç»ŸæŒ‡æ ‡"""
    timestamp: datetime
    
    # ä»»åŠ¡ç»Ÿè®¡
    total_tasks: int = 0
    running_tasks: int = 0
    pending_tasks: int = 0
    completed_tasks: int = 0
    failed_tasks: int = 0
    
    # æ€§èƒ½ç»Ÿè®¡
    avg_execution_time: float = 0.0
    avg_queue_time: float = 0.0
    success_rate: float = 0.0
    throughput_per_minute: float = 0.0
    
    # ç³»ç»Ÿèµ„æº
    cpu_usage_percent: float = 0.0
    memory_usage_mb: float = 0.0
    memory_usage_percent: float = 0.0
    
    # æ‰§è¡Œå™¨ç»Ÿè®¡
    cpu_executor_stats: Dict[str, Any] = field(default_factory=dict)
    io_executor_stats: Dict[str, Any] = field(default_factory=dict)


class TaskMonitor:
    """ä»»åŠ¡ç›‘æ§å™¨"""
    
    def __init__(self, max_history: int = 10000):
        """åˆå§‹åŒ–ä»»åŠ¡ç›‘æ§å™¨
        
        Args:
            max_history: æœ€å¤§å†å²è®°å½•æ•°
        """
        self.max_history = max_history
        
        # ä»»åŠ¡æŒ‡æ ‡å­˜å‚¨
        self.task_metrics: Dict[str, TaskMetrics] = {}
        self.completed_metrics: deque = deque(maxlen=max_history)
        
        # ç³»ç»ŸæŒ‡æ ‡å†å²
        self.system_metrics_history: deque = deque(maxlen=1000)
        
        # ç»Ÿè®¡è®¡æ•°å™¨
        self.counters = defaultdict(int)
        self.timers = defaultdict(list)
        
        # ç›‘æ§å›è°ƒ
        self.callbacks: List[Callable] = []
        
        # å¯åŠ¨æ—¶é—´
        self.start_time = datetime.utcnow()
        
        logger.info("ğŸ“Š ä»»åŠ¡ç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def record_task_created(self, task: TaskModel):
        """è®°å½•ä»»åŠ¡åˆ›å»º
        
        Args:
            task: ä»»åŠ¡æ¨¡å‹
        """
        metrics = TaskMetrics(
            task_id=task.task_id,
            task_type=task.task_type,
            status=task.status,
            created_at=task.created_at
        )
        
        self.task_metrics[task.task_id] = metrics
        self.counters[f"created_{task.task_type.value}"] += 1
        self.counters["total_created"] += 1
        
        logger.debug(f"ğŸ“Š è®°å½•ä»»åŠ¡åˆ›å»º: {task.task_id}")
    
    def record_task_started(self, task_id: str):
        """è®°å½•ä»»åŠ¡å¼€å§‹
        
        Args:
            task_id: ä»»åŠ¡ID
        """
        if task_id in self.task_metrics:
            metrics = self.task_metrics[task_id]
            metrics.started_at = datetime.utcnow()
            metrics.status = TaskStatus.RUNNING
            metrics.calculate_times()
            
            self.counters[f"started_{metrics.task_type.value}"] += 1
            self.counters["total_started"] += 1
            
            logger.debug(f"ğŸ“Š è®°å½•ä»»åŠ¡å¼€å§‹: {task_id}")
    
    def record_task_completed(self, 
                            task_id: str, 
                            success: bool = True,
                            error: Optional[str] = None,
                            retry_count: int = 0):
        """è®°å½•ä»»åŠ¡å®Œæˆ
        
        Args:
            task_id: ä»»åŠ¡ID
            success: æ˜¯å¦æˆåŠŸ
            error: é”™è¯¯ä¿¡æ¯
            retry_count: é‡è¯•æ¬¡æ•°
        """
        if task_id in self.task_metrics:
            metrics = self.task_metrics[task_id]
            metrics.completed_at = datetime.utcnow()
            metrics.status = TaskStatus.COMPLETED if success else TaskStatus.FAILED
            metrics.retry_count = retry_count
            metrics.calculate_times()
            
            # ç§»åŠ¨åˆ°å®ŒæˆæŒ‡æ ‡
            self.completed_metrics.append(metrics)
            del self.task_metrics[task_id]
            
            # æ›´æ–°è®¡æ•°å™¨
            status_key = "completed" if success else "failed"
            self.counters[f"{status_key}_{metrics.task_type.value}"] += 1
            self.counters[f"total_{status_key}"] += 1
            
            # è®°å½•æ‰§è¡Œæ—¶é—´
            if metrics.execution_time:
                self.timers[f"execution_time_{metrics.task_type.value}"].append(metrics.execution_time)
                self.timers["execution_time_all"].append(metrics.execution_time)
            
            # è®°å½•é˜Ÿåˆ—æ—¶é—´
            if metrics.queue_time:
                self.timers[f"queue_time_{metrics.task_type.value}"].append(metrics.queue_time)
                self.timers["queue_time_all"].append(metrics.queue_time)
            
            logger.debug(f"ğŸ“Š è®°å½•ä»»åŠ¡å®Œæˆ: {task_id} ({'æˆåŠŸ' if success else 'å¤±è´¥'})")
            
            # è§¦å‘å›è°ƒ
            self._trigger_callbacks("task_completed", {
                "task_id": task_id,
                "success": success,
                "metrics": metrics
            })
    
    def record_system_metrics(self, metrics: SystemMetrics):
        """è®°å½•ç³»ç»ŸæŒ‡æ ‡
        
        Args:
            metrics: ç³»ç»ŸæŒ‡æ ‡
        """
        self.system_metrics_history.append(metrics)
        logger.debug("ğŸ“Š è®°å½•ç³»ç»ŸæŒ‡æ ‡")
    
    def get_task_statistics(self, 
                          task_type: Optional[TaskType] = None,
                          time_range: Optional[timedelta] = None) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡ç»Ÿè®¡
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹è¿‡æ»¤
            time_range: æ—¶é—´èŒƒå›´è¿‡æ»¤
            
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        # è¿‡æ»¤æŒ‡æ ‡
        metrics_list = list(self.completed_metrics)
        
        if time_range:
            cutoff_time = datetime.utcnow() - time_range
            metrics_list = [m for m in metrics_list if m.completed_at and m.completed_at >= cutoff_time]
        
        if task_type:
            metrics_list = [m for m in metrics_list if m.task_type == task_type]
        
        # è®¡ç®—ç»Ÿè®¡
        total_tasks = len(metrics_list)
        if total_tasks == 0:
            return self._empty_statistics()
        
        # æŒ‰çŠ¶æ€ç»Ÿè®¡
        completed_tasks = len([m for m in metrics_list if m.status == TaskStatus.COMPLETED])
        failed_tasks = len([m for m in metrics_list if m.status == TaskStatus.FAILED])
        
        # è®¡ç®—æˆåŠŸç‡
        success_rate = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
        
        # è®¡ç®—å¹³å‡æ—¶é—´
        execution_times = [m.execution_time for m in metrics_list if m.execution_time]
        queue_times = [m.queue_time for m in metrics_list if m.queue_time]
        
        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0
        avg_queue_time = sum(queue_times) / len(queue_times) if queue_times else 0
        
        # è®¡ç®—ååé‡
        if time_range:
            throughput_per_minute = total_tasks / (time_range.total_seconds() / 60)
        else:
            uptime_minutes = (datetime.utcnow() - self.start_time).total_seconds() / 60
            throughput_per_minute = total_tasks / uptime_minutes if uptime_minutes > 0 else 0
        
        # æŒ‰ä»»åŠ¡ç±»å‹ç»Ÿè®¡
        by_type = defaultdict(int)
        for metrics in metrics_list:
            by_type[metrics.task_type.value] += 1
        
        return {
            "total_tasks": total_tasks,
            "completed_tasks": completed_tasks,
            "failed_tasks": failed_tasks,
            "running_tasks": len(self.task_metrics),
            "success_rate": round(success_rate, 2),
            "avg_execution_time": round(avg_execution_time, 3),
            "avg_queue_time": round(avg_queue_time, 3),
            "throughput_per_minute": round(throughput_per_minute, 2),
            "by_task_type": dict(by_type),
            "time_range": str(time_range) if time_range else "all_time"
        }
    
    def _empty_statistics(self) -> Dict[str, Any]:
        """ç©ºç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "running_tasks": 0,
            "success_rate": 0,
            "avg_execution_time": 0,
            "avg_queue_time": 0,
            "throughput_per_minute": 0,
            "by_task_type": {},
            "time_range": "empty"
        }
    
    def get_performance_trends(self, hours: int = 24) -> Dict[str, Any]:
        """è·å–æ€§èƒ½è¶‹åŠ¿
        
        Args:
            hours: å°æ—¶æ•°
            
        Returns:
            Dict[str, Any]: è¶‹åŠ¿æ•°æ®
        """
        cutoff_time = datetime.utcnow() - timedelta(hours=hours)
        
        # æŒ‰å°æ—¶åˆ†ç»„ç»Ÿè®¡
        hourly_stats = defaultdict(lambda: {"completed": 0, "failed": 0, "total_time": 0})
        
        for metrics in self.completed_metrics:
            if metrics.completed_at and metrics.completed_at >= cutoff_time:
                hour_key = metrics.completed_at.strftime("%Y-%m-%d %H:00")
                
                if metrics.status == TaskStatus.COMPLETED:
                    hourly_stats[hour_key]["completed"] += 1
                else:
                    hourly_stats[hour_key]["failed"] += 1
                
                if metrics.execution_time:
                    hourly_stats[hour_key]["total_time"] += metrics.execution_time
        
        # è½¬æ¢ä¸ºè¶‹åŠ¿æ•°æ®
        trends = []
        for hour, stats in sorted(hourly_stats.items()):
            total = stats["completed"] + stats["failed"]
            avg_time = stats["total_time"] / stats["completed"] if stats["completed"] > 0 else 0
            success_rate = (stats["completed"] / total * 100) if total > 0 else 0
            
            trends.append({
                "hour": hour,
                "total_tasks": total,
                "completed_tasks": stats["completed"],
                "failed_tasks": stats["failed"],
                "success_rate": round(success_rate, 2),
                "avg_execution_time": round(avg_time, 3)
            })
        
        return {
            "time_range_hours": hours,
            "trends": trends,
            "summary": {
                "total_hours": len(trends),
                "peak_hour": max(trends, key=lambda x: x["total_tasks"])["hour"] if trends else None,
                "avg_success_rate": round(sum(t["success_rate"] for t in trends) / len(trends), 2) if trends else 0
            }
        }
    
    def add_callback(self, callback: Callable):
        """æ·»åŠ ç›‘æ§å›è°ƒ
        
        Args:
            callback: å›è°ƒå‡½æ•°
        """
        self.callbacks.append(callback)
    
    def remove_callback(self, callback: Callable):
        """ç§»é™¤ç›‘æ§å›è°ƒ
        
        Args:
            callback: å›è°ƒå‡½æ•°
        """
        if callback in self.callbacks:
            self.callbacks.remove(callback)
    
    def _trigger_callbacks(self, event_type: str, data: Dict[str, Any]):
        """è§¦å‘å›è°ƒ
        
        Args:
            event_type: äº‹ä»¶ç±»å‹
            data: äº‹ä»¶æ•°æ®
        """
        for callback in self.callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    asyncio.create_task(callback(event_type, data))
                else:
                    callback(event_type, data)
            except Exception as e:
                logger.error(f"âŒ ç›‘æ§å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
    
    def get_real_time_metrics(self) -> Dict[str, Any]:
        """è·å–å®æ—¶æŒ‡æ ‡
        
        Returns:
            Dict[str, Any]: å®æ—¶æŒ‡æ ‡
        """
        # è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯
        try:
            import psutil
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()
            
            system_resources = {
                "cpu_usage_percent": cpu_percent,
                "memory_usage_mb": memory.used / 1024 / 1024,
                "memory_usage_percent": memory.percent,
                "available_memory_mb": memory.available / 1024 / 1024
            }
        except ImportError:
            system_resources = {}
        
        # å½“å‰è¿è¡Œä»»åŠ¡ç»Ÿè®¡
        running_by_type = defaultdict(int)
        for metrics in self.task_metrics.values():
            running_by_type[metrics.task_type.value] += 1
        
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "running_tasks": len(self.task_metrics),
            "running_by_type": dict(running_by_type),
            "completed_tasks_total": len(self.completed_metrics),
            "uptime_seconds": (datetime.utcnow() - self.start_time).total_seconds(),
            "system_resources": system_resources
        }
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.task_metrics.clear()
        self.completed_metrics.clear()
        self.system_metrics_history.clear()
        self.counters.clear()
        self.timers.clear()
        self.start_time = datetime.utcnow()
        
        logger.info("ğŸ”„ ä»»åŠ¡ç›‘æ§ç»Ÿè®¡å·²é‡ç½®")


# å…¨å±€ä»»åŠ¡ç›‘æ§å™¨å®ä¾‹
task_monitor = TaskMonitor()


logger.info("âœ… ä»»åŠ¡ç›‘æ§å’Œç»Ÿè®¡æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
