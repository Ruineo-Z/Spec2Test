"""
ä»»åŠ¡æ‰§è¡Œå™¨

æä¾›CPUå¯†é›†å‹å’ŒI/Oå¯†é›†å‹ä»»åŠ¡çš„ä¼˜åŒ–æ‰§è¡Œå™¨ã€‚
"""

import asyncio
import multiprocessing
import threading
import psutil
from typing import Any, Callable, Dict, Optional, List, Union
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, Future, as_completed
from datetime import datetime
from dataclasses import dataclass

from .models import TaskExecutionMode, TaskType
from app.core.shared.utils.logger import get_logger

logger = get_logger(__name__)


@dataclass
class ExecutorConfig:
    """æ‰§è¡Œå™¨é…ç½®"""
    max_workers: int
    thread_name_prefix: Optional[str] = None
    initializer: Optional[Callable] = None
    initargs: tuple = ()
    
    # è¿›ç¨‹æ± ç‰¹æœ‰é…ç½®
    mp_context: Optional[multiprocessing.context.BaseContext] = None
    max_tasks_per_child: Optional[int] = None
    
    # çº¿ç¨‹æ± ç‰¹æœ‰é…ç½®
    thread_name_prefix: Optional[str] = None


class OptimizedProcessPoolExecutor:
    """ä¼˜åŒ–çš„è¿›ç¨‹æ± æ‰§è¡Œå™¨"""
    
    def __init__(self, 
                 max_workers: Optional[int] = None,
                 mp_context: Optional[multiprocessing.context.BaseContext] = None,
                 initializer: Optional[Callable] = None,
                 initargs: tuple = (),
                 max_tasks_per_child: Optional[int] = None):
        """åˆå§‹åŒ–è¿›ç¨‹æ± æ‰§è¡Œå™¨
        
        Args:
            max_workers: æœ€å¤§å·¥ä½œè¿›ç¨‹æ•°
            mp_context: å¤šè¿›ç¨‹ä¸Šä¸‹æ–‡
            initializer: åˆå§‹åŒ–å‡½æ•°
            initargs: åˆå§‹åŒ–å‚æ•°
            max_tasks_per_child: æ¯ä¸ªå­è¿›ç¨‹æœ€å¤§ä»»åŠ¡æ•°
        """
        # è‡ªåŠ¨ç¡®å®šæœ€ä½³å·¥ä½œè¿›ç¨‹æ•°
        if max_workers is None:
            max_workers = min(32, (multiprocessing.cpu_count() or 1) + 4)
        
        self.max_workers = max_workers
        self.mp_context = mp_context
        self.initializer = initializer
        self.initargs = initargs
        self.max_tasks_per_child = max_tasks_per_child or 100  # é˜²æ­¢å†…å­˜æ³„æ¼
        
        # åˆ›å»ºè¿›ç¨‹æ± 
        self._executor = ProcessPoolExecutor(
            max_workers=self.max_workers,
            mp_context=self.mp_context,
            initializer=self.initializer,
            initargs=self.initargs,
            max_tasks_per_child=self.max_tasks_per_child
        )
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.submitted_tasks = 0
        self.completed_tasks = 0
        self.failed_tasks = 0
        self.start_time = datetime.utcnow()
        
        logger.info(f"ğŸ”§ ä¼˜åŒ–è¿›ç¨‹æ± æ‰§è¡Œå™¨åˆå§‹åŒ–: {self.max_workers} ä¸ªå·¥ä½œè¿›ç¨‹")
    
    async def submit(self, fn: Callable, *args, **kwargs) -> Any:
        """æäº¤ä»»åŠ¡åˆ°è¿›ç¨‹æ± 
        
        Args:
            fn: è¦æ‰§è¡Œçš„å‡½æ•°
            *args: ä½ç½®å‚æ•°
            **kwargs: å…³é”®å­—å‚æ•°
            
        Returns:
            Any: æ‰§è¡Œç»“æœ
        """
        self.submitted_tasks += 1
        
        try:
            # åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œè¿›ç¨‹æ± ä»»åŠ¡
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(self._executor, fn, *args, **kwargs)
            
            self.completed_tasks += 1
            return result
            
        except Exception as e:
            self.failed_tasks += 1
            logger.error(f"âŒ è¿›ç¨‹æ± ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    def submit_batch(self, fn: Callable, args_list: List[tuple]) -> List[Future]:
        """æ‰¹é‡æäº¤ä»»åŠ¡
        
        Args:
            fn: è¦æ‰§è¡Œçš„å‡½æ•°
            args_list: å‚æ•°åˆ—è¡¨
            
        Returns:
            List[Future]: Futureå¯¹è±¡åˆ—è¡¨
        """
        futures = []
        for args in args_list:
            future = self._executor.submit(fn, *args)
            futures.append(future)
            self.submitted_tasks += 1
        
        logger.info(f"ğŸ“¤ æ‰¹é‡æäº¤è¿›ç¨‹æ± ä»»åŠ¡: {len(futures)} ä¸ª")
        return futures
    
    async def submit_batch_async(self, fn: Callable, args_list: List[tuple]) -> List[Any]:
        """å¼‚æ­¥æ‰¹é‡æäº¤ä»»åŠ¡
        
        Args:
            fn: è¦æ‰§è¡Œçš„å‡½æ•°
            args_list: å‚æ•°åˆ—è¡¨
            
        Returns:
            List[Any]: æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        futures = self.submit_batch(fn, args_list)
        results = []
        
        for future in as_completed(futures):
            try:
                result = await asyncio.wrap_future(future)
                results.append(result)
                self.completed_tasks += 1
            except Exception as e:
                self.failed_tasks += 1
                logger.error(f"âŒ æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                results.append(None)
        
        return results
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œå™¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        uptime = (datetime.utcnow() - self.start_time).total_seconds()
        
        return {
            "executor_type": "ProcessPool",
            "max_workers": self.max_workers,
            "submitted_tasks": self.submitted_tasks,
            "completed_tasks": self.completed_tasks,
            "failed_tasks": self.failed_tasks,
            "success_rate": (self.completed_tasks / self.submitted_tasks * 100) if self.submitted_tasks > 0 else 0,
            "tasks_per_second": self.completed_tasks / uptime if uptime > 0 else 0,
            "uptime_seconds": uptime,
            "max_tasks_per_child": self.max_tasks_per_child
        }
    
    def shutdown(self, wait: bool = True):
        """å…³é—­æ‰§è¡Œå™¨
        
        Args:
            wait: æ˜¯å¦ç­‰å¾…ä»»åŠ¡å®Œæˆ
        """
        logger.info("ğŸ›‘ å…³é—­è¿›ç¨‹æ± æ‰§è¡Œå™¨")
        self._executor.shutdown(wait=wait)


class OptimizedThreadPoolExecutor:
    """ä¼˜åŒ–çš„çº¿ç¨‹æ± æ‰§è¡Œå™¨"""
    
    def __init__(self, 
                 max_workers: Optional[int] = None,
                 thread_name_prefix: str = "TaskThread",
                 initializer: Optional[Callable] = None,
                 initargs: tuple = ()):
        """åˆå§‹åŒ–çº¿ç¨‹æ± æ‰§è¡Œå™¨
        
        Args:
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
            thread_name_prefix: çº¿ç¨‹åç§°å‰ç¼€
            initializer: åˆå§‹åŒ–å‡½æ•°
            initargs: åˆå§‹åŒ–å‚æ•°
        """
        # è‡ªåŠ¨ç¡®å®šæœ€ä½³å·¥ä½œçº¿ç¨‹æ•°
        if max_workers is None:
            max_workers = min(32, (multiprocessing.cpu_count() or 1) * 4)
        
        self.max_workers = max_workers
        self.thread_name_prefix = thread_name_prefix
        self.initializer = initializer
        self.initargs = initargs
        
        # åˆ›å»ºçº¿ç¨‹æ± 
        self._executor = ThreadPoolExecutor(
            max_workers=self.max_workers,
            thread_name_prefix=self.thread_name_prefix,
            initializer=self.initializer,
            initargs=self.initargs
        )
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.submitted_tasks = 0
        self.completed_tasks = 0
        self.failed_tasks = 0
        self.start_time = datetime.utcnow()
        
        logger.info(f"ğŸ§µ ä¼˜åŒ–çº¿ç¨‹æ± æ‰§è¡Œå™¨åˆå§‹åŒ–: {self.max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
    
    async def submit(self, fn: Callable, *args, **kwargs) -> Any:
        """æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        
        Args:
            fn: è¦æ‰§è¡Œçš„å‡½æ•°
            *args: ä½ç½®å‚æ•°
            **kwargs: å…³é”®å­—å‚æ•°
            
        Returns:
            Any: æ‰§è¡Œç»“æœ
        """
        self.submitted_tasks += 1
        
        try:
            # åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œçº¿ç¨‹æ± ä»»åŠ¡
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(self._executor, fn, *args, **kwargs)
            
            self.completed_tasks += 1
            return result
            
        except Exception as e:
            self.failed_tasks += 1
            logger.error(f"âŒ çº¿ç¨‹æ± ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    def submit_batch(self, fn: Callable, args_list: List[tuple]) -> List[Future]:
        """æ‰¹é‡æäº¤ä»»åŠ¡
        
        Args:
            fn: è¦æ‰§è¡Œçš„å‡½æ•°
            args_list: å‚æ•°åˆ—è¡¨
            
        Returns:
            List[Future]: Futureå¯¹è±¡åˆ—è¡¨
        """
        futures = []
        for args in args_list:
            future = self._executor.submit(fn, *args)
            futures.append(future)
            self.submitted_tasks += 1
        
        logger.info(f"ğŸ“¤ æ‰¹é‡æäº¤çº¿ç¨‹æ± ä»»åŠ¡: {len(futures)} ä¸ª")
        return futures
    
    async def submit_batch_async(self, fn: Callable, args_list: List[tuple]) -> List[Any]:
        """å¼‚æ­¥æ‰¹é‡æäº¤ä»»åŠ¡
        
        Args:
            fn: è¦æ‰§è¡Œçš„å‡½æ•°
            args_list: å‚æ•°åˆ—è¡¨
            
        Returns:
            List[Any]: æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        futures = self.submit_batch(fn, args_list)
        results = []
        
        for future in as_completed(futures):
            try:
                result = await asyncio.wrap_future(future)
                results.append(result)
                self.completed_tasks += 1
            except Exception as e:
                self.failed_tasks += 1
                logger.error(f"âŒ æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                results.append(None)
        
        return results
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œå™¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        uptime = (datetime.utcnow() - self.start_time).total_seconds()
        
        return {
            "executor_type": "ThreadPool",
            "max_workers": self.max_workers,
            "submitted_tasks": self.submitted_tasks,
            "completed_tasks": self.completed_tasks,
            "failed_tasks": self.failed_tasks,
            "success_rate": (self.completed_tasks / self.submitted_tasks * 100) if self.submitted_tasks > 0 else 0,
            "tasks_per_second": self.completed_tasks / uptime if uptime > 0 else 0,
            "uptime_seconds": uptime,
            "active_threads": threading.active_count()
        }
    
    def shutdown(self, wait: bool = True):
        """å…³é—­æ‰§è¡Œå™¨
        
        Args:
            wait: æ˜¯å¦ç­‰å¾…ä»»åŠ¡å®Œæˆ
        """
        logger.info("ğŸ›‘ å…³é—­çº¿ç¨‹æ± æ‰§è¡Œå™¨")
        self._executor.shutdown(wait=wait)


class ExecutorManager:
    """æ‰§è¡Œå™¨ç®¡ç†å™¨"""
    
    def __init__(self, 
                 cpu_workers: Optional[int] = None,
                 io_workers: Optional[int] = None):
        """åˆå§‹åŒ–æ‰§è¡Œå™¨ç®¡ç†å™¨
        
        Args:
            cpu_workers: CPUå¯†é›†å‹ä»»åŠ¡å·¥ä½œè¿›ç¨‹æ•°
            io_workers: I/Oå¯†é›†å‹ä»»åŠ¡å·¥ä½œçº¿ç¨‹æ•°
        """
        # è‡ªåŠ¨é…ç½®å·¥ä½œè¿›ç¨‹/çº¿ç¨‹æ•°
        cpu_count = multiprocessing.cpu_count() or 1
        
        if cpu_workers is None:
            cpu_workers = cpu_count
        
        if io_workers is None:
            io_workers = cpu_count * 4
        
        # åˆ›å»ºæ‰§è¡Œå™¨
        self.cpu_executor = OptimizedProcessPoolExecutor(max_workers=cpu_workers)
        self.io_executor = OptimizedThreadPoolExecutor(max_workers=io_workers)
        
        # ä»»åŠ¡ç±»å‹åˆ°æ‰§è¡Œå™¨çš„æ˜ å°„
        self.task_executor_mapping = {
            TaskExecutionMode.CPU_INTENSIVE: self.cpu_executor,
            TaskExecutionMode.IO_INTENSIVE: self.io_executor,
            TaskExecutionMode.ASYNC_COROUTINE: None  # ç›´æ¥å¼‚æ­¥æ‰§è¡Œ
        }
        
        logger.info(f"âš™ï¸ æ‰§è¡Œå™¨ç®¡ç†å™¨åˆå§‹åŒ–: CPUå·¥ä½œè¿›ç¨‹={cpu_workers}, I/Oå·¥ä½œçº¿ç¨‹={io_workers}")
    
    async def execute_task(self, 
                          execution_mode: TaskExecutionMode,
                          fn: Callable,
                          *args,
                          **kwargs) -> Any:
        """æ‰§è¡Œä»»åŠ¡
        
        Args:
            execution_mode: æ‰§è¡Œæ¨¡å¼
            fn: è¦æ‰§è¡Œçš„å‡½æ•°
            *args: ä½ç½®å‚æ•°
            **kwargs: å…³é”®å­—å‚æ•°
            
        Returns:
            Any: æ‰§è¡Œç»“æœ
        """
        executor = self.task_executor_mapping.get(execution_mode)
        
        if executor is None:
            # å¼‚æ­¥åç¨‹ç›´æ¥æ‰§è¡Œ
            if asyncio.iscoroutinefunction(fn):
                return await fn(*args, **kwargs)
            else:
                # åŒæ­¥å‡½æ•°åŒ…è£…ä¸ºåç¨‹
                return await asyncio.to_thread(fn, *args, **kwargs)
        else:
            # ä½¿ç”¨å¯¹åº”çš„æ‰§è¡Œå™¨
            return await executor.submit(fn, *args, **kwargs)
    
    def get_optimal_execution_mode(self, task_type: TaskType) -> TaskExecutionMode:
        """è·å–ä»»åŠ¡ç±»å‹çš„æœ€ä¼˜æ‰§è¡Œæ¨¡å¼
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            
        Returns:
            TaskExecutionMode: æ‰§è¡Œæ¨¡å¼
        """
        # æ ¹æ®ä»»åŠ¡ç±»å‹ç‰¹æ€§é€‰æ‹©æ‰§è¡Œæ¨¡å¼
        if task_type == TaskType.DOCUMENT_ANALYSIS:
            return TaskExecutionMode.CPU_INTENSIVE  # æ–‡æ¡£è§£ææ˜¯CPUå¯†é›†å‹
        elif task_type == TaskType.TEST_GENERATION:
            return TaskExecutionMode.CPU_INTENSIVE  # æµ‹è¯•ç”Ÿæˆæ˜¯CPUå¯†é›†å‹
        elif task_type == TaskType.TEST_EXECUTION:
            return TaskExecutionMode.IO_INTENSIVE   # æµ‹è¯•æ‰§è¡Œæ˜¯I/Oå¯†é›†å‹
        elif task_type == TaskType.REPORT_GENERATION:
            return TaskExecutionMode.CPU_INTENSIVE  # æŠ¥å‘Šç”Ÿæˆæ˜¯CPUå¯†é›†å‹
        else:
            return TaskExecutionMode.ASYNC_COROUTINE  # é»˜è®¤å¼‚æ­¥æ‰§è¡Œ
    
    def get_system_resources(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯
        
        Returns:
            Dict[str, Any]: ç³»ç»Ÿèµ„æºä¿¡æ¯
        """
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            return {
                "cpu_count": multiprocessing.cpu_count(),
                "cpu_percent": cpu_percent,
                "memory_total_gb": memory.total / (1024**3),
                "memory_available_gb": memory.available / (1024**3),
                "memory_percent": memory.percent,
                "active_threads": threading.active_count()
            }
        except Exception as e:
            logger.error(f"âŒ è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œå™¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            "cpu_executor": self.cpu_executor.get_statistics(),
            "io_executor": self.io_executor.get_statistics(),
            "system_resources": self.get_system_resources()
        }
    
    def shutdown(self, wait: bool = True):
        """å…³é—­æ‰€æœ‰æ‰§è¡Œå™¨
        
        Args:
            wait: æ˜¯å¦ç­‰å¾…ä»»åŠ¡å®Œæˆ
        """
        logger.info("ğŸ›‘ å…³é—­æ‰§è¡Œå™¨ç®¡ç†å™¨")
        self.cpu_executor.shutdown(wait=wait)
        self.io_executor.shutdown(wait=wait)


# å…¨å±€æ‰§è¡Œå™¨ç®¡ç†å™¨å®ä¾‹
executor_manager = ExecutorManager()


logger.info("âœ… ä»»åŠ¡æ‰§è¡Œå™¨æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
